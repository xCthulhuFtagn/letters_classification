{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PIL.ImageFont.FreeTypeFont at 0x7fbd4362ee90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_list = [ \n",
    "    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf',\n",
    "    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf',\n",
    "    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf',\n",
    "    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf',\n",
    "    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf',\n",
    "    '/usr/local/lib/python3.10/dist-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf',\n",
    " ]\n",
    " \n",
    "import random\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font = ImageFont.truetype(random.choice(font_list), size=random.randint(100, 200))\n",
    "font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"./data/test\"): os.mkdir(\"./data/test\")\n",
    "if not os.path.exists(\"./data/train\"): os.mkdir(\"./data/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пилим пикчу на составные и работаем с ними как с отдельными изображениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.MAX_IMAGE_PIXELS = 900000000\n",
    "\n",
    "# img = Image.open('/home/owner/Documents/DEV/DL/hw-letters-xCthulhuFtagn/letters_58.png')\n",
    "\n",
    "# for i in range(100):\n",
    "#     for j in range(100):\n",
    "#         new_img = img.crop((300*i,300*j, 300*(i+1), 300*(j+1)))\n",
    "#         new_img.save(f\"./data/test/letter_{(i+1) + j*100}.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерим свои данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://stackoverflow.com/questions/75344148/trying-to-use-python-pil-imagedraw-textbbox-because-of-textsize-deprecation-but\n",
    "# from string import ascii_uppercase\n",
    "# from random import randint\n",
    "# import math\n",
    "# import numpy as np\n",
    "\n",
    "# classes = (set(ascii_uppercase) - {'N', 'Z'} - {'M', 'W'}).union({\"N_Z\", \"M_W\"})\n",
    "# for letter in classes:\n",
    "#     for i in range(100):\n",
    "#         empty = Image.new('RGBA', (300, 300), (255, 255,255, 255))\n",
    "#         overlay = Image.new('RGBA', (300, 300), (255, 255, 255, 0))\n",
    "        \n",
    "#         empty_draw = ImageDraw.Draw(empty)\n",
    "#         n_circles = randint(10, 40)\n",
    "#         for _ in range(n_circles):\n",
    "#             circle = Image.new('RGBA', (300, 300), (255, 255,255, 0))\n",
    "#             circle_draw = ImageDraw.Draw(circle)\n",
    "#             color = (random.randint(0, 200), \n",
    "#                      random.randint(0, 200), \n",
    "#                      random.randint(0, 200),\n",
    "#                      random.randint(50, 70))\n",
    "#             x = randint(10, 290)\n",
    "#             y = randint(10, 290)\n",
    "#             radius = randint(1, 35)\n",
    "#             xy = [x - radius, y - radius, x + radius, y + radius]\n",
    "#             circle_draw.ellipse(xy, fill=color)\n",
    "#             empty = Image.alpha_composite(empty, circle)\n",
    "        \n",
    "#         overlay_draw = ImageDraw.Draw(overlay)\n",
    "#         spin_angle = randint(0, 359)\n",
    "#         radians = math.radians(spin_angle)\n",
    "#         spread = 0\n",
    "#         x, y = 150 + randint(-spread, spread), 150 + randint(-spread, spread)\n",
    "        \n",
    "#         if letter == \"N_Z\": label = \"N\" if np.random.random() < 0.5 else \"Z\"\n",
    "#         elif letter == \"M_W\": label = \"M\" if np.random.random() < 0.5 else \"W\"\n",
    "#         else: label = letter\n",
    "        \n",
    "#         overlay_draw.text(\n",
    "#             (x, y),\n",
    "#             text=label,\n",
    "#             font=font,\n",
    "#             fill=(randint(0, 255), randint(0, 255), randint(0, 255), 255),\n",
    "#         )\n",
    "        \n",
    "#         new_img = Image.alpha_composite(empty, overlay.rotate(spin_angle))\n",
    "#         new_img = new_img.convert('RGB')\n",
    "#         new_img.save(f\"./data/train/{letter}_{i}.png\", 'PNG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Херачим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from string import ascii_uppercase\n",
    "\n",
    "class DatasetLetters(Dataset):\n",
    "    def __init__(self, root='./data', train=True, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.classes = (set(ascii_uppercase) - {'N', 'Z'} - {'M', 'W'}).union({\"N_Z\", \"M_W\"})\n",
    "        self.classes = dict(zip(range(len(self.classes)), self.classes))\n",
    "        self.len = len(os.listdir(self.root + \"/train\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load image\n",
    "        # transform image\n",
    "        # return dict with image and class label\n",
    "        letter = self.classes[index // 100]\n",
    "        sub_index = index % 100\n",
    "        file_name = f\"{letter}_{sub_index}.png\"\n",
    "        pic = cv2.imread(self.root + \"/train/\" + file_name)\n",
    "        # labels = torch.zeros(24).type(torch.LongTensor)\n",
    "        # labels[index // 100] = 1\n",
    "        return {\"image\": self.transform(pic), \"label\": torch.Tensor([index // 100]).type(torch.LongTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LetterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=3) #100x100x6\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=1, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=4, stride=4) #25x25x4\n",
    "        self.lin = nn.Linear(in_features=625, out_features=100)\n",
    "        self.final = nn.Linear(in_features=100, out_features=24)\n",
    "    \n",
    "    def forward(self, x : torch.Tensor):\n",
    "        # print(f\"x: {x.shape}\")\n",
    "        x.to(\"cuda:0\")\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.lin(x.flatten(2)))\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [128, 6, 300, 300]             168\n",
      "         MaxPool2d-2         [128, 6, 100, 100]               0\n",
      "            Conv2d-3         [128, 1, 100, 100]              55\n",
      "         MaxPool2d-4           [128, 1, 25, 25]               0\n",
      "            Linear-5              [128, 1, 100]          62,600\n",
      "            Linear-6               [128, 1, 24]           2,424\n",
      "================================================================\n",
      "Total params: 65,247\n",
      "Trainable params: 65,247\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 131.84\n",
      "Forward/backward pass size (MB): 596.43\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 728.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model=LetterCNN().to(\"cuda:0\"), input_size=(3,300,300), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input.shape, target.shape)\n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, train_dataset, batch_size=128):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_dataset = train_dataset\n",
    "        self.lossF = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.device = 'cpu'\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.cuda.current_device()\n",
    "            self.model = self.model.to(self.device)\n",
    "\n",
    "        self.global_step = 0\n",
    "\n",
    "    def save_checkpoint(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        \n",
    "    def load_checkpoint(self, path):\n",
    "        self.model = torch.load(path)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        model = self.model\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        train_loader = DataLoader(self.train_dataset, shuffle=True, pin_memory=True, batch_size=self.batch_size)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for batch in tqdm(train_loader):\n",
    "                x = batch[\"image\"].to(self.device)\n",
    "                y = torch.Tensor(batch[\"label\"]).to(self.device)\n",
    "                \n",
    "                logits = model.forward(x)\n",
    "                print(logits.shape, y.shape)\n",
    "                \n",
    "                loss = self.lossF(logits, y)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                self.global_step += 1\n",
    "                \n",
    "    def classify(self):\n",
    "        path = self.path + \"/test\"\n",
    "        \n",
    "        classes = self.train_dataset.classes\n",
    "        \n",
    "        letters_df = pd.read_csv(\"/home/owner/Documents/DEV/DL/hw-letters-xCthulhuFtagn/letters.csv\")\n",
    "        \n",
    "        letters_df.values = 0\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            \n",
    "            pic = cv2.imread(filename)\n",
    "            logits = self.model(pic)\n",
    "            \n",
    "            letter = classes[np.argmax(logits)]\n",
    "            if letter == \"N/Z\":\n",
    "                if np.random.random() < 0.5: letters_df[\"N\"] += 1\n",
    "                else: letters_df[\"Z\"] += 1\n",
    "            elif letter == \"M/W\":\n",
    "                if np.random.random() < 0.5: letters_df[\"M\"] += 1\n",
    "                else: letters_df[\"W\"] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_dataset = DatasetLetters(transform=transform_to_tensor)\n",
    "model = LetterCNN()\n",
    "\n",
    "trainer = Trainer(model, torch.optim.Adam(model.parameters()), train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 24]) torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [128, 24], got [128, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 43\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m logits \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 43\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlossF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     46\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/DEV/DL/hw-letters-xCthulhuFtagn/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DEV/DL/hw-letters-xCthulhuFtagn/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/DEV/DL/hw-letters-xCthulhuFtagn/.venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DEV/DL/hw-letters-xCthulhuFtagn/.venv/lib/python3.10/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [128, 24], got [128, 1]"
     ]
    }
   ],
   "source": [
    "trainer.train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32]) torch.Size([128, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1245)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "inputs = torch.rand(128, 3, 32)\n",
    "targets = torch.ones(128, 32)\n",
    "print(inputs.shape, targets.shape)\n",
    "loss(inputs, targets.long())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
